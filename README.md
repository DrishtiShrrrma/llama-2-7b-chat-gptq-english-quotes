#### Tip:

1. Monitor GPU Memory: Use torch.cuda.memory_allocated() and torch.cuda.memory_cached() to monitor GPU memory usage.
2. Clear GPU Cache: Releasing unused memory can help:

![image](https://github.com/DrishtiShrrrma/llama-2-7b-chat-gptq-english-quotes/assets/129742046/91860b8e-c3f6-406a-a7f3-92ac908ea2fb)

![image](https://github.com/DrishtiShrrrma/llama-2-7b-chat-gptq-english-quotes/assets/129742046/379e25ef-71c7-4066-951e-907d8fa5526b)

